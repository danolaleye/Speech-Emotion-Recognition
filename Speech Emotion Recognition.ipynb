{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Speech Emotion Recognition.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1JRcfinHeAcS8PBiIOKlIergccykg5Ekn","authorship_tag":"ABX9TyOUUSiDm4OynL9FJJgW/P++"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"trkkKpq6Chfa","colab_type":"text"},"source":["# Speech Emotion Recognition\n"]},{"cell_type":"markdown","metadata":{"id":"rn041eDEadcP","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"FfB8z1lpadoz","colab_type":"text"},"source":["### Starters Code"]},{"cell_type":"code","metadata":{"id":"qIpUNvIGznZE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ddde08f3-35cf-45df-8001-adfb2025665c","executionInfo":{"status":"ok","timestamp":1591856165120,"user_tz":240,"elapsed":1285,"user":{"displayName":"Daniel Olaleye","photoUrl":"","userId":"03898532523128989737"}}},"source":["# To use google colab's GPU\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":70,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6g98per-cMU4","colab_type":"code","colab":{}},"source":["#!pip install soundfile\n","import librosa\n","import soundfile\n","import os, glob, pickle\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p6IYNDPiieTC","colab_type":"text"},"source":["*We need to extract mfcc, chroma, and mel features from the soundfile. Let's define a function to do that. This function will take in 4 parameters (the filename and three boolean parameters for the three features)*"]},{"cell_type":"code","metadata":{"id":"ElFniD3zkYcx","colab_type":"code","colab":{}},"source":["def extract_features(file_name, mfcc, chroma, mel):\n","    with soundfile.SoundFile(file_name) as sound_file:\n","        X = sound_file.read(dtype = \"float32\")\n","        sample_rate = sound_file.samplerate\n","        if chroma:\n","            stft = np.abs(librosa.stft(X))\n","        result = np.array([])\n","        if mfcc:\n","            mfcc = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc = 40).T,axis=0)\n","            result = np.hstack((result, mfcc))\n","        if chroma:\n","            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n","            result = np.hstack((result, chroma))\n","        if mel:\n","            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T, axis = 0)\n","            result = np.hstack((result, mel))\n","        return result"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s3mKtR3Znwlt","colab_type":"code","colab":{}},"source":["# Define a dictionary to hold emotions and numbers in the RAVDESS dataset\n","emotions = {\n","    '01':'neutral',\n","    '02':'calm',\n","    '03':'happy',\n","    '04':'sad',\n","    '05':'angry',\n","    '06':'fearful',\n","    '07':'disgust',\n","    '08':'surprised'\n","}\n","\n","# Define a list to hold the emotions we want\n","observed_emotions = ['calm','happy','fearful','disgust']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nSxPWVZBppYS","colab_type":"text"},"source":["## Load the Data"]},{"cell_type":"code","metadata":{"id":"2SM6lOUuA0TQ","colab_type":"code","colab":{}},"source":["# Define your file path\n","file_path = \"/content/drive/My Drive/Colab Notebooks/Personal Projects/Speech Emotion Recognition/Data/speech-emotion-recognition-ravdess-data/Actor_*/*.wav\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I1-cqMNfpyzh","colab_type":"code","colab":{}},"source":["#define a load_data function using glob() function in the glob module to get all the pathnames for the files in our dataset\n","\n","\n","def load_data(test_size=0.2):\n","    x,y=[], []\n","    for file in glob.glob(file_path):\n","        file_name = os.path.basename(file)\n","        emotion = emotions[file_name.split('-')[2]]\n","        if emotion not in observed_emotions:\n","            continue\n","        feature = extract_features(file, mfcc=True, chroma=True, mel=True)\n","        x.append(feature)\n","        y.append(emotion)\n","    return train_test_split(np.array(x), y, test_size = test_size, random_state = 42)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EWw2QZKNuPV4","colab_type":"text"},"source":["## Train Test Split"]},{"cell_type":"code","metadata":{"id":"yzyC8pikuWsq","colab_type":"code","colab":{}},"source":["X_train, X_test, y_train, y_test = load_data(test_size=0.25)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TaSQqqsXvN4y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5c73c120-b996-4836-d068-0ef9c38b3aae","executionInfo":{"status":"ok","timestamp":1591856199752,"user_tz":240,"elapsed":35774,"user":{"displayName":"Daniel Olaleye","photoUrl":"","userId":"03898532523128989737"}}},"source":["print((X_train.shape[0], X_test.shape[0]))"],"execution_count":77,"outputs":[{"output_type":"stream","text":["(576, 192)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FWtQ_nIIuGsi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"be697276-fd13-4053-ffd5-34bafddb258b","executionInfo":{"status":"ok","timestamp":1591856199760,"user_tz":240,"elapsed":35738,"user":{"displayName":"Daniel Olaleye","photoUrl":"","userId":"03898532523128989737"}}},"source":["# get the number of features extracted\n","print(f'Features extracted: {X_train.shape[1]}')"],"execution_count":78,"outputs":[{"output_type":"stream","text":["Features extracted: 180\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y7aRRM3d6KYa","colab_type":"text"},"source":["## The Model Using MLP (Multi Layer Perceptron)"]},{"cell_type":"code","metadata":{"id":"csyn5eP36l67","colab_type":"code","colab":{}},"source":["model = MLPClassifier(alpha=0.001, batch_size=16, hidden_layer_sizes=(350,),learning_rate_init=0.0001, learning_rate='adaptive', max_iter=500)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jAO02PNQ6Qgt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"d8ca03bd-f751-41b7-8242-eb14afbf1136","executionInfo":{"status":"ok","timestamp":1591856224123,"user_tz":240,"elapsed":60060,"user":{"displayName":"Daniel Olaleye","photoUrl":"","userId":"03898532523128989737"}}},"source":["# Train the model\n","model.fit(X_train, y_train)"],"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MLPClassifier(activation='relu', alpha=0.001, batch_size=16, beta_1=0.9,\n","              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n","              hidden_layer_sizes=(350,), learning_rate='adaptive',\n","              learning_rate_init=0.0001, max_fun=15000, max_iter=500,\n","              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n","              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n","              tol=0.0001, validation_fraction=0.1, verbose=False,\n","              warm_start=False)"]},"metadata":{"tags":[]},"execution_count":80}]},{"cell_type":"code","metadata":{"id":"30cI3FR9kVWh","colab_type":"code","colab":{}},"source":["# Prediction\n","y_pred = model.predict(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6N9YcGqPiULl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4e97bcda-e4fe-4425-874f-f02688b2e8d2","executionInfo":{"status":"ok","timestamp":1591856224131,"user_tz":240,"elapsed":60018,"user":{"displayName":"Daniel Olaleye","photoUrl":"","userId":"03898532523128989737"}}},"source":["#Accuracy of the model\n","accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n","\n","print(f\"Accuracy: {round(accuracy*100,2)}%\")"],"execution_count":82,"outputs":[{"output_type":"stream","text":["Accuracy: 77.08%\n"],"name":"stdout"}]}]}